{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bitf8540139ee00427484eeaf07a0d58c9d",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *arg, **kwargs):\n",
    "        super().__init__(*arg, **kwargs)\n",
    "        self.padding = (self.kernel_size[0] //2, self.kernel_size[1] //2)\n",
    "\n",
    "conv3x3 = partial(Conv2dAuto, kernel_size = 3, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = conv3x3(in_channels = 32, out_channels = 64)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels =  in_channels, out_channels\n",
    "        self.blocks = nn.Identity()\n",
    "        self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResidualBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.ones((1, 1, 1, 1))\n",
    "\n",
    "block = ResidualBlock(1, 64)\n",
    "block(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(OrderedDict(\n",
    "        {\n",
    "            'conv' : nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1, # expansion expanded_channels are same thing?\n",
    "                      stride=self.downsampling, bias=False),\n",
    "            'bn' : nn.BatchNorm2d(self.expanded_channels)\n",
    "            \n",
    "        })) if self.should_apply_shortcut else nn.Identity() # None\n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    # @property\n",
    "    # def should_apply_shortcut(self):\n",
    "    #     return self.in_channels != self.expanded_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNetResidualBlock(32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(OrderedDict({'conv' : conv(in_channels, out_channels,*args, **kwargs),\n",
    "                                    'bn' : nn.BatchNorm2d(out_channels)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bn(3, 3, nn.Conv2d, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation(),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy = torch.ones((1, 32, 224, 224))\n",
    "\n",
    "block = ResNetBasicBlock(32, 64)\n",
    "print(block(dummy).shape)\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
    "             activation(),\n",
    "             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
    "             activation(),\n",
    "             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 256, 10, 10])\nResNetBottleNeckBlock(\n  (blocks): Sequential(\n    (0): Sequential(\n      (conv): Conv2dAuto(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): ReLU()\n    (2): Sequential(\n      (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): ReLU()\n    (4): Sequential(\n      (conv): Conv2dAuto(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (shortcut): Sequential(\n    (conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)\n"
    }
   ],
   "source": [
    "dummy = torch.ones((1, 32, 10, 10))\n",
    "\n",
    "block = ResNetBottleNeckBlock(32, 64)\n",
    "print(block(dummy).shape)\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "\n",
    "        self.blocks = nn.Sequential(block(in_channels, out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "                                    *[block(out_channels * block.expansion, out_channels, downsampling=1, *args, **kwargs) for _ in range(n-1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 128, 24, 24])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ResNetLayer(\n  (blocks): Sequential(\n    (0): ResNetBasicBlock(\n      (blocks): Sequential(\n        (0): Sequential(\n          (conv): Conv2dAuto(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (1): ReLU()\n        (2): Sequential(\n          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (shortcut): Sequential(\n        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): ResNetBasicBlock(\n      (blocks): Sequential(\n        (0): Sequential(\n          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (1): ReLU()\n        (2): Sequential(\n          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (shortcut): Identity()\n    )\n    (2): ResNetBasicBlock(\n      (blocks): Sequential(\n        (0): Sequential(\n          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (1): ReLU()\n        (2): Sequential(\n          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (shortcut): Identity()\n    )\n  )\n)"
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "dummy = torch.ones((1, 64, 48, 48))\n",
    "\n",
    "layer = ResNetLayer(64, 128, block=ResNetBasicBlock, n=3)\n",
    "print(layer(dummy).shape)\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n",
    "                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks_sizes = blocks_sizes\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
    "            activation(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
    "        # self.blocks = nn.ModuleList([ \n",
    "        #     ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n",
    "        #                 block=block,  *args, **kwargs),\n",
    "        #     *[ResNetLayer(in_channels * block.expansion, \n",
    "        #                   out_channels, n=n, activation=activation, \n",
    "        #                   block=block, *args, **kwargs) \n",
    "        #       for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
    "        # ])\n",
    "        self.blocks = nn.Sequential( \n",
    "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n",
    "                        block=block,  *args, **kwargs),\n",
    "            *[ResNetLayer(in_channels * block.expansion, \n",
    "                          out_channels, n=n, activation=activation, \n",
    "                          block=block, *args, **kwargs) \n",
    "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        x = self.blocks(x)\n",
    "        # for block in self.blocks:\n",
    "        #     x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetDecoder(nn.Module):\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.decoder = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
    "        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[2, 2, 2, 2])\n",
    "\n",
    "def resnet34(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[3, 4, 6, 3])\n",
    "\n",
    "def resnet50(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 6, 3])\n",
    "\n",
    "def resnet101(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 23, 3])\n",
    "\n",
    "def resnet152(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 8, 36, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 122, 122]           9,408\n       BatchNorm2d-2         [-1, 64, 122, 122]             128\n              ReLU-3         [-1, 64, 122, 122]               0\n         MaxPool2d-4           [-1, 64, 61, 61]               0\n        Conv2dAuto-5           [-1, 64, 61, 61]          36,864\n       BatchNorm2d-6           [-1, 64, 61, 61]             128\n              ReLU-7           [-1, 64, 61, 61]               0\n        Conv2dAuto-8           [-1, 64, 61, 61]          36,864\n       BatchNorm2d-9           [-1, 64, 61, 61]             128\n ResNetBasicBlock-10           [-1, 64, 61, 61]               0\n       Conv2dAuto-11           [-1, 64, 61, 61]          36,864\n      BatchNorm2d-12           [-1, 64, 61, 61]             128\n             ReLU-13           [-1, 64, 61, 61]               0\n       Conv2dAuto-14           [-1, 64, 61, 61]          36,864\n      BatchNorm2d-15           [-1, 64, 61, 61]             128\n ResNetBasicBlock-16           [-1, 64, 61, 61]               0\n      ResNetLayer-17           [-1, 64, 61, 61]               0\n           Conv2d-18          [-1, 128, 31, 31]           8,192\n      BatchNorm2d-19          [-1, 128, 31, 31]             256\n       Conv2dAuto-20          [-1, 128, 31, 31]          73,728\n      BatchNorm2d-21          [-1, 128, 31, 31]             256\n             ReLU-22          [-1, 128, 31, 31]               0\n       Conv2dAuto-23          [-1, 128, 31, 31]         147,456\n      BatchNorm2d-24          [-1, 128, 31, 31]             256\n ResNetBasicBlock-25          [-1, 128, 31, 31]               0\n       Conv2dAuto-26          [-1, 128, 31, 31]         147,456\n      BatchNorm2d-27          [-1, 128, 31, 31]             256\n             ReLU-28          [-1, 128, 31, 31]               0\n       Conv2dAuto-29          [-1, 128, 31, 31]         147,456\n      BatchNorm2d-30          [-1, 128, 31, 31]             256\n ResNetBasicBlock-31          [-1, 128, 31, 31]               0\n      ResNetLayer-32          [-1, 128, 31, 31]               0\n           Conv2d-33          [-1, 256, 16, 16]          32,768\n      BatchNorm2d-34          [-1, 256, 16, 16]             512\n       Conv2dAuto-35          [-1, 256, 16, 16]         294,912\n      BatchNorm2d-36          [-1, 256, 16, 16]             512\n             ReLU-37          [-1, 256, 16, 16]               0\n       Conv2dAuto-38          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-39          [-1, 256, 16, 16]             512\n ResNetBasicBlock-40          [-1, 256, 16, 16]               0\n       Conv2dAuto-41          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-42          [-1, 256, 16, 16]             512\n             ReLU-43          [-1, 256, 16, 16]               0\n       Conv2dAuto-44          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-45          [-1, 256, 16, 16]             512\n ResNetBasicBlock-46          [-1, 256, 16, 16]               0\n      ResNetLayer-47          [-1, 256, 16, 16]               0\n           Conv2d-48            [-1, 512, 8, 8]         131,072\n      BatchNorm2d-49            [-1, 512, 8, 8]           1,024\n       Conv2dAuto-50            [-1, 512, 8, 8]       1,179,648\n      BatchNorm2d-51            [-1, 512, 8, 8]           1,024\n             ReLU-52            [-1, 512, 8, 8]               0\n       Conv2dAuto-53            [-1, 512, 8, 8]       2,359,296\n      BatchNorm2d-54            [-1, 512, 8, 8]           1,024\n ResNetBasicBlock-55            [-1, 512, 8, 8]               0\n       Conv2dAuto-56            [-1, 512, 8, 8]       2,359,296\n      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n             ReLU-58            [-1, 512, 8, 8]               0\n       Conv2dAuto-59            [-1, 512, 8, 8]       2,359,296\n      BatchNorm2d-60            [-1, 512, 8, 8]           1,024\n ResNetBasicBlock-61            [-1, 512, 8, 8]               0\n      ResNetLayer-62            [-1, 512, 8, 8]               0\n    ResNetEncoder-63            [-1, 512, 8, 8]               0\nAdaptiveAvgPool2d-64            [-1, 512, 1, 1]               0\n           Linear-65                 [-1, 1000]         513,000\n    ResnetDecoder-66                 [-1, 1000]               0\n================================================================\nTotal params: 11,689,512\nTrainable params: 11,689,512\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.68\nForward/backward pass size (MB): 72.84\nParams size (MB): 44.59\nEstimated Total Size (MB): 118.11\n----------------------------------------------------------------\n"
    }
   ],
   "source": [
    "model = resnet18(3, 1000)\n",
    "summary(model,(3,244,244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "# writer = SummaryWriter('runs/mnist1')\n",
    "writer = SummaryWriter('runs/test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, torch.rand(1,3,244,244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 244, 244])"
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "torch.rand(3,244,244).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "test_model = models.resnet18(False)\n",
    "writer.add_graph(test_model, torch.rand(1,3,244,244))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ResNet(\n  (encoder): ResNetEncoder(\n    (gate): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )\n    (blocks): ModuleList(\n      (0): ResNetLayer(\n        (blocks): Sequential(\n          (0): ResNetBasicBlock(\n            (blocks): Sequential(\n              (0): Sequential(\n                (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (1): ReLU()\n              (2): Sequential(\n                (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (shortcut): None\n          )\n          (1): ResNetBasicBlock(\n            (blocks): Sequential(\n              (0): Sequential(\n                (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (1): ReLU()\n              (2): Sequential(\n                (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (shortcut): None\n          )\n        )\n      )\n      (1): ResNetLayer(\n        (blocks): Sequential(\n          (0): ResNetBasicBlock(\n            (blocks): Sequential(\n              (0): Sequential(\n                (conv): Conv2dAuto(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (1): ReLU()\n              (2): Sequential(\n                (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (shortcut): Sequential(\n              (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (1): ResNetBasicBlock(\n            (blocks): Sequential(\n              (0): Sequential(\n                (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (1): ReLU()\n              (2): Sequential(\n                (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (shortcut): None\n          )\n        )\n      )\n      (2): ResNetLayer(\n        (blocks): Sequential(\n          (0): ResNetBasicBlock(\n            (blocks): Sequential(\n              (0): Sequential(\n                (conv): Conv2dAuto(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (1): ReLU()\n              (2): Sequential(\n                (conv): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (shortcut): Sequential(\n              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (1): ResNetBasicBlock(\n            (blocks): Sequential(\n              (0): Sequential(\n                (conv): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (1): ReLU()\n              (2): Sequential(\n                (conv): Conv2dAuto(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (shortcut): None\n          )\n        )\n      )\n      (3): ResNetLayer(\n        (blocks): Sequential(\n          (0): ResNetBasicBlock(\n            (blocks): Sequential(\n              (0): Sequential(\n                (conv): Conv2dAuto(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (1): ReLU()\n              (2): Sequential(\n                (conv): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (shortcut): Sequential(\n              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n          )\n          (1): ResNetBasicBlock(\n            (blocks): Sequential(\n              (0): Sequential(\n                (conv): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (1): ReLU()\n              (2): Sequential(\n                (conv): Conv2dAuto(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n            )\n            (shortcut): None\n          )\n        )\n      )\n    )\n  )\n  (decoder): ResnetDecoder(\n    (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n    (decoder): Linear(in_features=512, out_features=10, bias=True)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 169
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}