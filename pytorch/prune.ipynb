{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596158878167",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<bound method Module.modules of LeNet(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<bound method Module.children of LeNet(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<bound method Module.named_children of LeNet(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.named_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<bound method Module.named_modules of LeNet(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('weight',\n  Parameter containing:\n  tensor([[[[-0.2487,  0.3102,  0.2069],\n            [-0.0560, -0.1190, -0.3054],\n            [-0.1513, -0.0013,  0.1598]]],\n  \n  \n          [[[-0.3121, -0.2036, -0.0970],\n            [-0.1208,  0.0731, -0.0441],\n            [ 0.3108, -0.1555,  0.3227]]],\n  \n  \n          [[[-0.0645, -0.0914, -0.0298],\n            [ 0.3153, -0.1837,  0.1004],\n            [ 0.0495,  0.3147, -0.1659]]],\n  \n  \n          [[[ 0.2732,  0.0143,  0.2799],\n            [ 0.2853,  0.0012, -0.2103],\n            [-0.2442,  0.3331, -0.2162]]],\n  \n  \n          [[[ 0.2175,  0.2603,  0.0033],\n            [-0.0258,  0.1743,  0.2421],\n            [ 0.2314, -0.1907, -0.1123]]],\n  \n  \n          [[[-0.1852,  0.2778, -0.0128],\n            [-0.1567,  0.1004, -0.1757],\n            [ 0.1725,  0.0271,  0.2683]]]], requires_grad=True)),\n ('bias',\n  Parameter containing:\n  tensor([ 0.0315, -0.3157, -0.0437,  0.1053, -0.2900, -0.1562],\n         requires_grad=True))]"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "module = model.conv1\n",
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "prune.random_unstructured(module, name='weight', amount=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('bias',\n  Parameter containing:\n  tensor([ 0.0315, -0.3157, -0.0437,  0.1053, -0.2900, -0.1562],\n         requires_grad=True)),\n ('weight_orig',\n  Parameter containing:\n  tensor([[[[-0.2487,  0.3102,  0.2069],\n            [-0.0560, -0.1190, -0.3054],\n            [-0.1513, -0.0013,  0.1598]]],\n  \n  \n          [[[-0.3121, -0.2036, -0.0970],\n            [-0.1208,  0.0731, -0.0441],\n            [ 0.3108, -0.1555,  0.3227]]],\n  \n  \n          [[[-0.0645, -0.0914, -0.0298],\n            [ 0.3153, -0.1837,  0.1004],\n            [ 0.0495,  0.3147, -0.1659]]],\n  \n  \n          [[[ 0.2732,  0.0143,  0.2799],\n            [ 0.2853,  0.0012, -0.2103],\n            [-0.2442,  0.3331, -0.2162]]],\n  \n  \n          [[[ 0.2175,  0.2603,  0.0033],\n            [-0.0258,  0.1743,  0.2421],\n            [ 0.2314, -0.1907, -0.1123]]],\n  \n  \n          [[[-0.1852,  0.2778, -0.0128],\n            [-0.1567,  0.1004, -0.1757],\n            [ 0.1725,  0.0271,  0.2683]]]], requires_grad=True))]"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('weight_mask',\n  tensor([[[[1., 0., 1.],\n            [1., 0., 1.],\n            [1., 1., 1.]]],\n  \n  \n          [[[1., 1., 1.],\n            [1., 1., 0.],\n            [1., 1., 1.]]],\n  \n  \n          [[[1., 1., 1.],\n            [0., 1., 1.],\n            [1., 1., 0.]]],\n  \n  \n          [[[1., 1., 1.],\n            [0., 0., 1.],\n            [1., 0., 1.]]],\n  \n  \n          [[[1., 1., 1.],\n            [0., 1., 0.],\n            [1., 0., 0.]]],\n  \n  \n          [[[0., 1., 1.],\n            [0., 1., 1.],\n            [1., 0., 0.]]]]))]"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[[-0.2487,  0.0000,  0.2069],\n          [-0.0560, -0.0000, -0.3054],\n          [-0.1513, -0.0013,  0.1598]]],\n\n\n        [[[-0.3121, -0.2036, -0.0970],\n          [-0.1208,  0.0731, -0.0000],\n          [ 0.3108, -0.1555,  0.3227]]],\n\n\n        [[[-0.0645, -0.0914, -0.0298],\n          [ 0.0000, -0.1837,  0.1004],\n          [ 0.0495,  0.3147, -0.0000]]],\n\n\n        [[[ 0.2732,  0.0143,  0.2799],\n          [ 0.0000,  0.0000, -0.2103],\n          [-0.2442,  0.0000, -0.2162]]],\n\n\n        [[[ 0.2175,  0.2603,  0.0033],\n          [-0.0000,  0.1743,  0.0000],\n          [ 0.2314, -0.0000, -0.0000]]],\n\n\n        [[[-0.0000,  0.2778, -0.0128],\n          [-0.0000,  0.1004, -0.1757],\n          [ 0.1725,  0.0000,  0.0000]]]], grad_fn=<MulBackward0>)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured at 0x7efcd7556828>)])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "module._forward_pre_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "prune.l1_unstructured(module, 'bias', amount=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('weight_orig',\n  Parameter containing:\n  tensor([[[[-0.2487,  0.3102,  0.2069],\n            [-0.0560, -0.1190, -0.3054],\n            [-0.1513, -0.0013,  0.1598]]],\n  \n  \n          [[[-0.3121, -0.2036, -0.0970],\n            [-0.1208,  0.0731, -0.0441],\n            [ 0.3108, -0.1555,  0.3227]]],\n  \n  \n          [[[-0.0645, -0.0914, -0.0298],\n            [ 0.3153, -0.1837,  0.1004],\n            [ 0.0495,  0.3147, -0.1659]]],\n  \n  \n          [[[ 0.2732,  0.0143,  0.2799],\n            [ 0.2853,  0.0012, -0.2103],\n            [-0.2442,  0.3331, -0.2162]]],\n  \n  \n          [[[ 0.2175,  0.2603,  0.0033],\n            [-0.0258,  0.1743,  0.2421],\n            [ 0.2314, -0.1907, -0.1123]]],\n  \n  \n          [[[-0.1852,  0.2778, -0.0128],\n            [-0.1567,  0.1004, -0.1757],\n            [ 0.1725,  0.0271,  0.2683]]]], requires_grad=True)),\n ('bias_orig',\n  Parameter containing:\n  tensor([ 0.0315, -0.3157, -0.0437,  0.1053, -0.2900, -0.1562],\n         requires_grad=True))]"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('weight_mask',\n  tensor([[[[1., 0., 1.],\n            [1., 0., 1.],\n            [1., 1., 1.]]],\n  \n  \n          [[[1., 1., 1.],\n            [1., 1., 0.],\n            [1., 1., 1.]]],\n  \n  \n          [[[1., 1., 1.],\n            [0., 1., 1.],\n            [1., 1., 0.]]],\n  \n  \n          [[[1., 1., 1.],\n            [0., 0., 1.],\n            [1., 0., 1.]]],\n  \n  \n          [[[1., 1., 1.],\n            [0., 1., 0.],\n            [1., 0., 0.]]],\n  \n  \n          [[[0., 1., 1.],\n            [0., 1., 1.],\n            [1., 0., 0.]]]])),\n ('bias_mask', tensor([0., 1., 0., 0., 1., 1.]))]"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ 0.0000, -0.3157, -0.0000,  0.0000, -0.2900, -0.1562],\n       grad_fn=<MulBackward0>)"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "module.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured at 0x7efcd7556828>),\n             (1, <torch.nn.utils.prune.L1Unstructured at 0x7efcd7437940>)])"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "module._forward_pre_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "prune.ln_structured(module, name='weight', amount=0.5, n=2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[[-0.2487,  0.0000,  0.2069],\n          [-0.0560, -0.0000, -0.3054],\n          [-0.1513, -0.0013,  0.1598]]],\n\n\n        [[[-0.3121, -0.2036, -0.0970],\n          [-0.1208,  0.0731, -0.0000],\n          [ 0.3108, -0.1555,  0.3227]]],\n\n\n        [[[-0.0000, -0.0000, -0.0000],\n          [ 0.0000, -0.0000,  0.0000],\n          [ 0.0000,  0.0000, -0.0000]]],\n\n\n        [[[ 0.2732,  0.0143,  0.2799],\n          [ 0.0000,  0.0000, -0.2103],\n          [-0.2442,  0.0000, -0.2162]]],\n\n\n        [[[ 0.0000,  0.0000,  0.0000],\n          [-0.0000,  0.0000,  0.0000],\n          [ 0.0000, -0.0000, -0.0000]]],\n\n\n        [[[-0.0000,  0.0000, -0.0000],\n          [-0.0000,  0.0000, -0.0000],\n          [ 0.0000,  0.0000,  0.0000]]]], grad_fn=<MulBackward0>)"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OrderedDict([(1, <torch.nn.utils.prune.L1Unstructured at 0x7efcd7437940>),\n             (2, <torch.nn.utils.prune.PruningContainer at 0x7efcd7423940>)])"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "module._forward_pre_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[<torch.nn.utils.prune.RandomUnstructured object at 0x7efcd7556828>, <torch.nn.utils.prune.LnStructured object at 0x7efcd7423ac8>]\n"
    }
   ],
   "source": [
    "for hook in module._forward_pre_hooks.values():\n",
    "    if hook._tensor_name == \"weight\":  # select out the correct hook\n",
    "        break\n",
    "\n",
    "print(list(hook))  # pruning history in the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<torch.nn.utils.prune.RandomUnstructured at 0x7efcd7556828>,\n <torch.nn.utils.prune.LnStructured at 0x7efcd7423ac8>]"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "list(list(module._forward_pre_hooks.values())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('weight_orig',\n  Parameter containing:\n  tensor([[[[-0.2487,  0.3102,  0.2069],\n            [-0.0560, -0.1190, -0.3054],\n            [-0.1513, -0.0013,  0.1598]]],\n  \n  \n          [[[-0.3121, -0.2036, -0.0970],\n            [-0.1208,  0.0731, -0.0441],\n            [ 0.3108, -0.1555,  0.3227]]],\n  \n  \n          [[[-0.0645, -0.0914, -0.0298],\n            [ 0.3153, -0.1837,  0.1004],\n            [ 0.0495,  0.3147, -0.1659]]],\n  \n  \n          [[[ 0.2732,  0.0143,  0.2799],\n            [ 0.2853,  0.0012, -0.2103],\n            [-0.2442,  0.3331, -0.2162]]],\n  \n  \n          [[[ 0.2175,  0.2603,  0.0033],\n            [-0.0258,  0.1743,  0.2421],\n            [ 0.2314, -0.1907, -0.1123]]],\n  \n  \n          [[[-0.1852,  0.2778, -0.0128],\n            [-0.1567,  0.1004, -0.1757],\n            [ 0.1725,  0.0271,  0.2683]]]], requires_grad=True)),\n ('bias_orig',\n  Parameter containing:\n  tensor([ 0.0315, -0.3157, -0.0437,  0.1053, -0.2900, -0.1562],\n         requires_grad=True))]"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('weight_mask',\n  tensor([[[[1., 0., 1.],\n            [1., 0., 1.],\n            [1., 1., 1.]]],\n  \n  \n          [[[1., 1., 1.],\n            [1., 1., 0.],\n            [1., 1., 1.]]],\n  \n  \n          [[[0., 0., 0.],\n            [0., 0., 0.],\n            [0., 0., 0.]]],\n  \n  \n          [[[1., 1., 1.],\n            [0., 0., 1.],\n            [1., 0., 1.]]],\n  \n  \n          [[[0., 0., 0.],\n            [0., 0., 0.],\n            [0., 0., 0.]]],\n  \n  \n          [[[0., 0., 0.],\n            [0., 0., 0.],\n            [0., 0., 0.]]]])),\n ('bias_mask', tensor([0., 1., 0., 0., 1., 1.]))]"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[[-0.2487,  0.0000,  0.2069],\n          [-0.0560, -0.0000, -0.3054],\n          [-0.1513, -0.0013,  0.1598]]],\n\n\n        [[[-0.3121, -0.2036, -0.0970],\n          [-0.1208,  0.0731, -0.0000],\n          [ 0.3108, -0.1555,  0.3227]]],\n\n\n        [[[-0.0000, -0.0000, -0.0000],\n          [ 0.0000, -0.0000,  0.0000],\n          [ 0.0000,  0.0000, -0.0000]]],\n\n\n        [[[ 0.2732,  0.0143,  0.2799],\n          [ 0.0000,  0.0000, -0.2103],\n          [-0.2442,  0.0000, -0.2162]]],\n\n\n        [[[ 0.0000,  0.0000,  0.0000],\n          [-0.0000,  0.0000,  0.0000],\n          [ 0.0000, -0.0000, -0.0000]]],\n\n\n        [[[-0.0000,  0.0000, -0.0000],\n          [-0.0000,  0.0000, -0.0000],\n          [ 0.0000,  0.0000,  0.0000]]]], grad_fn=<MulBackward0>)"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('bias_mask', tensor([0., 1., 0., 0., 1., 1.]))]"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "prune.remove(module, 'weight')\n",
    "\n",
    "list(module.named_buffers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('',\n  LeNet(\n    (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n    (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n    (fc1): Linear(in_features=400, out_features=120, bias=True)\n    (fc2): Linear(in_features=120, out_features=84, bias=True)\n    (fc3): Linear(in_features=84, out_features=10, bias=True)\n  )),\n ('conv1', Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))),\n ('conv2', Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))),\n ('fc1', Linear(in_features=400, out_features=120, bias=True)),\n ('fc2', Linear(in_features=120, out_features=84, bias=True)),\n ('fc3', Linear(in_features=84, out_features=10, bias=True))]"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "list(new_model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=iter(new_model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('conv2', Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)))"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "next(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, module in new_model.named_modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "dict(new_model.named_buffers()).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    "    (model.fc3, 'weight'),\n",
    ")\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.conv1.weight == 0))\n",
    "        / float(model.conv1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.conv2.weight == 0))\n",
    "        / float(model.conv2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc1.weight == 0))\n",
    "        / float(model.fc1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc2.weight == 0))\n",
    "        / float(model.fc2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc3.weight == 0))\n",
    "        / float(model.fc3.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "            + torch.sum(model.fc1.weight == 0)\n",
    "            + torch.sum(model.fc2.weight == 0)\n",
    "            + torch.sum(model.fc3.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "            + model.fc1.weight.nelement()\n",
    "            + model.fc2.weight.nelement()\n",
    "            + model.fc3.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(8.2176)"
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "torch.sum(model.conv2.weight == 0) / float(model.conv2.weight.nelement()) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}