{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0.0120, 0.0889, 0.2418, 0.6572])\ntensor([0.0120, 0.0889, 0.2418, 0.6572])\n"
    }
   ],
   "source": [
    "#softmax\n",
    "output = torch.softmax(x,dim=0)\n",
    "print(output)\n",
    "sm = nn.Softmax(dim=0)\n",
    "output = sm(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0.2689, 0.7311, 0.8808, 0.9526])\ntensor([0.2689, 0.7311, 0.8808, 0.9526])\n"
    }
   ],
   "source": [
    "#sigmoid\n",
    "output = torch.sigmoid(x)\n",
    "print(output)\n",
    "sig = nn.Sigmoid()\n",
    "output = sig(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\ntensor([-0.7616,  0.7616,  0.9640,  0.9951])\n"
    }
   ],
   "source": [
    "#tanh\n",
    "output = torch.tanh(x)\n",
    "print(output)\n",
    "th = nn.Tanh()\n",
    "output = th(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0., 1., 2., 3.])\ntensor([0., 1., 2., 3.])\n"
    }
   ],
   "source": [
    "#relu\n",
    "output = torch.relu(x)\n",
    "print(output)\n",
    "rl = nn.ReLU()\n",
    "output = rl(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\ntensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
    }
   ],
   "source": [
    "#leaky relu\n",
    "output = F.leaky_relu(x)\n",
    "print(output)\n",
    "lrl = nn.LeakyReLU()\n",
    "output = lrl(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
    "#torch.relu on the other side is just the functional API call to the relu function,\n",
    "#so that you can add it e.g. in your forward method yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1 (create nn modules)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 2 (use activation functions directly in forward pass)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bit3407b1b345654694a2a82fb5d1f176f1",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}